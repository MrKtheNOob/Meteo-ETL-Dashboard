# Rapport de Projet : Pipeline ETL M√©t√©o et Entrep√¥t de Donn√©es

## Introduction

Durant ce projet, un pipeline ETL (Extract, Transform, Load) enti√®rement fonctionnel a √©t√© con√ßu et mis en ≈ìuvre pour collecter, traiter et stocker des donn√©es m√©t√©orologiques provenant de l'API [WeatherAPI.com](https://www.weatherapi.com/) dans un entrep√¥t de donn√©es centralis√©.  
En parall√®le, un tableau de bord a √©t√© d√©velopp√© pour visualiser les donn√©es et valider l'int√©grit√© et l'exploitabilit√© du pipeline.

## Approche et Architecture

En raison des contraintes de compatibilit√© et d'installation avec les outils ETL GUI lourds (par exemple, Talend, SSIS), un syst√®me ETL personnalis√© bas√© sur Python a √©t√© choisi. Cette d√©cision a permis un meilleur contr√¥le, une it√©ration rapide et une compr√©hension approfondie de chaque √©tape du flux de donn√©es.

Le pipeline a √©t√© con√ßu pour :

- R√©cup√©rer s√©quentiellement les donn√©es pour chaque ville via l'API WeatherAPI.com.
- Traiter et nettoyer les donn√©es brutes.
- Les ins√©rer initialement dans une base de donn√©es source relationnelle.
- G√©rer les limitations de l'API et les contraintes CPU des instances gratuites gr√¢ce √† un cadencement intelligent (`time.sleep()`).

## Conception des Sch√©mas de Base de Donn√©es

### Sch√©ma de la Base de Donn√©es Source

Un sch√©ma relationnel a √©t√© cr√©√© pour la base source, destin√©e √† la capture initiale des donn√©es m√©t√©orologiques actuelles et des pr√©visions. Ce sch√©ma est optimis√© pour les op√©rations transactionnelles, minimisant la redondance et assurant l'int√©grit√© des donn√©es.

### Sch√©ma de l'Entrep√¥t de Donn√©es (Sch√©ma en √âtoile)

Un sch√©ma en √©toile a √©t√© choisi pour l'entrep√¥t de donn√©es, optimis√© pour l'analyse et le reporting. Il est compos√© :

- D'une table de faits centrale (`FaitDonneesMeteo`) pour les mesures m√©t√©orologiques horaires.
- De tables de dimensions connect√©es (`DimLieux`, `DimConditionsMeteo`, `DimTemps`).

Ce choix facilite l'exploration des donn√©es et am√©liore les performances analytiques.

## Processus ETL et Algorithmes de Transformation

Les donn√©es brutes extraites de l'API ont √©t√© transform√©es pour passer d‚Äôun format transactionnel √† une structure d√©normalis√©e adapt√©e au sch√©ma en √©toile. Les √©tapes comprenaient :

- Parsing et validation des JSON via Pydantic.
- Mappage des attributs aux tables de faits et de dimensions.
- D√©composition des horodatages (ann√©e, mois, jour, heure, minute) pour la dimension temps.
- Insertion des donn√©es transform√©es dans les tables via `pymysql`, en g√©rant explicitement les transactions pour assurer la coh√©rence.

## API de Donn√©es M√©t√©o

Une API a √©t√© d√©velopp√©e en Flask pour exposer les donn√©es de l'entrep√¥t :

- `/trigger-etl` (GET) : D√©clenche le processus ETL en arri√®re-plan.
- `/etl-status` (GET) : Statut actuel du processus ETL (en cours, termin√©, erreur).
- `/api/weather/all` (GET) : Toutes les donn√©es m√©t√©o disponibles.
- `/api/weather/locations` (GET) : Liste des villes disponibles.
- `/` (GET) : Sert le frontend (index.html).
- `/<path:filename>` (GET) : Sert les fichiers statiques (JS, CSS, etc.).

L'utilisation de Flask-Caching a permis d‚Äôoptimiser les r√©ponses, et le traitement ETL est ex√©cut√© dans un thread s√©par√© pour ne pas bloquer les requ√™tes API.

## Cron-Jobs

La logique ETL a √©t√© encapsul√©e pour √™tre d√©clench√©e par des t√¢ches planifi√©es (cron jobs), notamment via [cron-job.org](https://cron-job.org/) pour appeler `/trigger-etl`.

## Tableau de Bord et Validation

Un tableau de bord interactif a √©t√© d√©velopp√© avec React et des librairies de visualisation modernes. Il interroge directement l‚ÄôAPI Flask et permet une exploration dynamique et une validation des donn√©es.  

üîó **Tableau de bord en ligne** : [https://meteo-etl-dashboard.onrender.com/](https://meteo-etl-dashboard.onrender.com/)

## D√©fis Cl√©s

- **Limitations des outils** : Incapacit√© d‚Äôutiliser des ETL GUI (Talend, SSIS), n√©cessitant une approche cod√©e.
- **Contraintes de ressources** : Limites CPU/RAM strictes, n√©cessitant des optimisations pour √©viter les plantages.
- **Contraintes DB** : Probl√®mes de cl√©s et relations, r√©solus par des insertions s√©quentielles et gestion explicite des transactions.

## Int√©gration Additionnelle (Airflow)

Apr√®s la finalisation du pipeline Python, un prototype local Airflow a √©t√© int√©gr√© pour d√©montrer la compr√©hension des orchestrateurs utilis√©s en entreprise.

## Le√ßons Apprises

- Conception compl√®te d'un pipeline ETL, orchestration, gestion des erreurs et ressources.
- Compr√©hension de l‚Äô√©quilibre entre simplicit√©, maintenabilit√© et conformit√© aux standards.
- Optimisation et d√©ploiement sous contraintes strictes.
- Pratique du d√©bogage et am√©lioration it√©rative bas√©e sur les retours du syst√®me.

## Conclusion

Ce projet a permis d‚Äôatteindre les objectifs fondamentaux d‚ÄôETL et d‚Äôentrep√¥t de donn√©es tout en fournissant une exp√©rience r√©aliste et orient√©e production.  
Il a renforc√© les comp√©tences techniques et strat√©giques en ing√©nierie des donn√©es gr√¢ce √† une combinaison de r√©solution de probl√®mes, conception de syst√®mes et flexibilit√© de pens√©e.
