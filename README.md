# Rapport de Projet : Pipeline ETL M√©t√©o et Entrep√¥t de Donn√©es

## Introduction

Durant ce projet, un pipeline ETL (Extract, Transform, Load) enti√®rement fonctionnel a √©t√© con√ßu et mis en ≈ìuvre pour collecter, traiter et stocker des donn√©es m√©t√©orologiques provenant de l'API [WeatherAPI.com](https://www.weatherapi.com/) dans un entrep√¥t de donn√©es centralis√©.  
En parall√®le, un tableau de bord a √©t√© d√©velopp√© pour visualiser les donn√©es et valider l'int√©grit√© et l'exploitabilit√© du pipeline.

## Approche et Architecture

En raison des contraintes de compatibilit√© et d'installation avec les outils ETL GUI lourds (par exemple, Talend, SSIS), un syst√®me ETL personnalis√© bas√© sur Python a √©t√© choisi. Cette d√©cision a permis un meilleur contr√¥le, une it√©ration rapide et une compr√©hension approfondie de chaque √©tape du flux de donn√©es.

Le pipeline a √©t√© con√ßu pour :

- R√©cup√©rer s√©quentiellement les donn√©es pour chaque ville via l'API WeatherAPI.com.
- Traiter et nettoyer les donn√©es brutes.
- Les ins√©rer initialement dans une base de donn√©es source relationnelle.
- G√©rer les limitations de l'API et les contraintes CPU des instances gratuites gr√¢ce √† un cadencement intelligent (`time.sleep()`).

## Conception des Sch√©mas de Base de Donn√©es

### Sch√©ma de la Base de Donn√©es Source

Un sch√©ma relationnel a √©t√© cr√©√© pour la base source, destin√©e √† la capture initiale des donn√©es m√©t√©orologiques actuelles et des pr√©visions. Ce sch√©ma est optimis√© pour les op√©rations transactionnelles, minimisant la redondance et assurant l'int√©grit√© des donn√©es.

### Sch√©ma de l'Entrep√¥t de Donn√©es (Sch√©ma en √âtoile)

Un sch√©ma en √©toile a √©t√© choisi pour l'entrep√¥t de donn√©es, optimis√© pour l'analyse et le reporting. Il est compos√© :

- D'une table de faits centrale (`FaitDonneesMeteo`) pour les mesures m√©t√©orologiques horaires.
- De tables de dimensions connect√©es (`DimLieux`, `DimConditionsMeteo`, `DimTemps`).

Ce choix facilite l'exploration des donn√©es et am√©liore les performances analytiques.

## Processus ETL et Algorithmes de Transformation

Les donn√©es brutes extraites de l'API ont √©t√© transform√©es pour passer d‚Äôun format transactionnel √† une structure d√©normalis√©e adapt√©e au sch√©ma en √©toile. Les √©tapes comprenaient :

- Parsing et validation des JSON via Pydantic.
- Mappage des attributs aux tables de faits et de dimensions.
- D√©composition des horodatages (ann√©e, mois, jour, heure, minute) pour la dimension temps.
- Insertion des donn√©es transform√©es dans les tables via `pymysql`, en g√©rant explicitement les transactions pour assurer la coh√©rence.

## API de Donn√©es M√©t√©o

Une API a √©t√© d√©velopp√©e en Flask pour exposer les donn√©es de l'entrep√¥t :

- `/trigger-etl` (GET) : D√©clenche le processus ETL en arri√®re-plan.
- `/etl-status` (GET) : Statut actuel du processus ETL (en cours, termin√©, erreur).
- `/api/weather/all` (GET) : Toutes les donn√©es m√©t√©o disponibles.
- `/api/weather/locations` (GET) : Liste des villes disponibles.
- `/` (GET) : Sert le frontend (index.html).
- `/<path:filename>` (GET) : Sert les fichiers statiques (JS, CSS, etc.).

L'utilisation de Flask-Caching a permis d‚Äôoptimiser les r√©ponses, et le traitement ETL est ex√©cut√© dans un thread s√©par√© pour ne pas bloquer les requ√™tes API.

## Cron-Jobs

La logique ETL a √©t√© encapsul√©e pour √™tre d√©clench√©e par des t√¢ches planifi√©es (cron jobs), notamment via [cron-job.org](https://cron-job.org/) pour appeler `/trigger-etl`.

## Tableau de Bord et Validation

Un tableau de bord interactif a √©t√© d√©velopp√© avec React et des librairies de visualisation modernes. Il interroge directement l‚ÄôAPI Flask et permet une exploration dynamique et une validation des donn√©es.  

üîó **Tableau de bord en ligne** : [https://meteo-etl-dashboard.onrender.com/](https://meteo-etl-dashboard.onrender.com/)

## D√©fis Cl√©s

- **Limitations des outils** : Incapacit√© d‚Äôutiliser des ETL GUI (Talend, SSIS), n√©cessitant une approche cod√©e.
- **Contraintes de ressources** : Limites CPU/RAM strictes, n√©cessitant des optimisations pour √©viter les plantages.
- **Contraintes DB** : Probl√®mes de cl√©s et relations, r√©solus par des insertions s√©quentielles et gestion explicite des transactions.

## Int√©gration Additionnelle (Airflow)

Apr√®s la finalisation du pipeline Python, un prototype local Airflow a √©t√© int√©gr√© pour d√©montrer la compr√©hension des orchestrateurs utilis√©s en entreprise.

## Le√ßons Apprises

- Conception compl√®te d'un pipeline ETL, orchestration, gestion des erreurs et ressources.
- Compr√©hension de l‚Äô√©quilibre entre simplicit√©, maintenabilit√© et conformit√© aux standards.
- Optimisation et d√©ploiement sous contraintes strictes.
- Pratique du d√©bogage et am√©lioration it√©rative bas√©e sur les retours du syst√®me.

## Conclusion

Ce projet a permis d‚Äôatteindre les objectifs fondamentaux d‚ÄôETL et d‚Äôentrep√¥t de donn√©es tout en fournissant une exp√©rience r√©aliste et orient√©e production.  
Il a renforc√© les comp√©tences techniques et strat√©giques en ing√©nierie des donn√©es gr√¢ce √† une combinaison de r√©solution de probl√®mes, conception de syst√®mes et flexibilit√© de pens√©e.

# Configuration de Airflow

```
. ‚îú‚îÄ‚îÄ airflow
‚îÇ ‚îú‚îÄ‚îÄ airflow.cfg
‚îÇ ‚îú‚îÄ‚îÄ airflow.db
‚îÇ ‚îú‚îÄ‚îÄ dags
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ weather_etl_dag.py
‚îÇ ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ ‚îú‚îÄ‚îÄ dockerfile
```

---

## ‚úÖ Pr√©requis

* Docker et Docker Compose install√©s
* Connaissances de base du terminal

---

## Contenu du dossier expliqu√©

* `airflow.cfg` ‚Äî Fichier de configuration Airflow
* `airflow.db` ‚Äî Base de donn√©es SQLite locale pour les m√©tadonn√©es Airflow (si vous n'utilisez pas de base de donn√©es externe)
* `dags/` ‚Äî Votre Les DAG se trouvent ici (par exemple, `weather_etl_dag.py`)
* `docker-compose.yml` ‚Äî D√©finit les services et comment ex√©cuter Airflow dans les conteneurs
* `dockerfile` ‚Äî D√©finition d'une image personnalis√©e (par exemple, pour installer des packages suppl√©mentaires)

---

## Cr√©er l'image Docker Airflow

Dans le r√©pertoire `airflow`¬†:

```bash
cd airflow
docker build -t custom-airflow:latest -f dockerfile . ```

---

## ‚öôÔ∏è V√©rifier / modifier `docker-compose.yml`

Assurez-vous que `docker-compose.yml` utilise l'image personnalis√©e que vous venez de cr√©er¬†:

```yaml
version¬†: '3'
services¬†:
airflow¬†:
image¬†: custom-airflow:latest
environnement¬†:
- AIRFLOW__CORE__LOAD_EXAMPLES=False
- AIRFLOW__CORE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
volumes¬†:
- ./dags:/opt/airflow/dags
- ./airflow.cfg:/opt/airflow/airflow.cfg
- ./airflow.db:/opt/airflow/airflow.db
ports¬†:
- "8080:8080"
commande¬†: Serveur web
```

---

## D√©marrer Airflow

```bash
docker-compose up
```

* Ceci ex√©cute le serveur web Airflow √† l'adresse **[http://localhost:8080](http://localhost:8080)**
* Par d√©faut, aucun ordonnanceur n'est ex√©cut√© s√©par√©ment. Si n√©cessaire, ajoutez-le √† `docker-compose.yml` comme service suppl√©mentaire.

---

## Initialiser la base de donn√©es (uniquement lors de la premi√®re ex√©cution)

Si c'est votre premi√®re ex√©cution¬†:

```bash
docker-compose run airflow airflow db init
```

Puis red√©marrez¬†:

```bash
docker-compose up
```

---

## Acc√©der √† l'interface utilisateur d'Airflow

* Ouvrir **[http://localhost:8080](http://localhost:8080)**
* Identifiants par d√©faut¬†: `airflow` / `airflow` (si inchang√©)

---

## V√©rifiez votre DAG

Dans l'interface utilisateur, vous devriez voir `weather_etl_dag.py` list√©.
Activez-le et d√©clenchez-le si n√©cessaire.

---

## Arr√™ter Airflow

```bash
docker-compose down
```

---

## üí¨ Remarques

* Vous utilisez **SQLite**, parfait pour les tests locaux. En production, utilisez Postgres ou MySQL.
* Votre `airflow.db` est stock√© sous forme de fichier et mont√©, ce qui garantit la persistance des donn√©es apr√®s le red√©marrage du conteneur.
* Personnalisez `dockerfile` pour installer des packages Python ou des outils syst√®me selon vos besoins (par exemple, `RUN pip install requests`).


## ‚úÖ R√©sum√©

1Ô∏è‚É£ Construire votre image
2Ô∏è‚É£ V√©rifier que `docker-compose.yml` pointe vers elle
3Ô∏è‚É£ Ex√©cuter `docker-compose up`
4Ô∏è‚É£ Acc√©der √† l'interface utilisateur √† `localhost:8080`

---
