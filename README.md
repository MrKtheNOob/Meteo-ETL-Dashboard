# Rapport de Projet : Pipeline ETL MÃ©tÃ©o et EntrepÃ´t de DonnÃ©es

## Introduction

Durant ce projet, un pipeline ETL (Extract, Transform, Load) entiÃ¨rement fonctionnel a Ã©tÃ© conÃ§u et mis en Å“uvre pour collecter, traiter et stocker des donnÃ©es mÃ©tÃ©orologiques provenant de l'API [WeatherAPI.com](https://www.weatherapi.com/) dans un entrepÃ´t de donnÃ©es centralisÃ©.  
En parallÃ¨le, un tableau de bord a Ã©tÃ© dÃ©veloppÃ© pour visualiser les donnÃ©es et valider l'intÃ©gritÃ© et l'exploitabilitÃ© du pipeline.

## Approche et Architecture

En raison des contraintes de compatibilitÃ© et d'installation avec les outils ETL GUI lourds (par exemple, Talend, SSIS), un systÃ¨me ETL personnalisÃ© basÃ© sur Python a Ã©tÃ© choisi. Cette dÃ©cision a permis un meilleur contrÃ´le, une itÃ©ration rapide et une comprÃ©hension approfondie de chaque Ã©tape du flux de donnÃ©es.

Le pipeline a Ã©tÃ© conÃ§u pour :

- RÃ©cupÃ©rer sÃ©quentiellement les donnÃ©es pour chaque ville via l'API WeatherAPI.com.
- Traiter et nettoyer les donnÃ©es brutes.
- Les insÃ©rer initialement dans une base de donnÃ©es source relationnelle.
- GÃ©rer les limitations de l'API et les contraintes CPU des instances gratuites grÃ¢ce Ã  un cadencement intelligent (`time.sleep()`).

## Conception des SchÃ©mas de Base de DonnÃ©es

### SchÃ©ma de la Base de DonnÃ©es Source

Un schÃ©ma relationnel a Ã©tÃ© crÃ©Ã© pour la base source, destinÃ©e Ã  la capture initiale des donnÃ©es mÃ©tÃ©orologiques actuelles et des prÃ©visions. Ce schÃ©ma est optimisÃ© pour les opÃ©rations transactionnelles, minimisant la redondance et assurant l'intÃ©gritÃ© des donnÃ©es.

### SchÃ©ma de l'EntrepÃ´t de DonnÃ©es (SchÃ©ma en Ã‰toile)

Un schÃ©ma en Ã©toile a Ã©tÃ© choisi pour l'entrepÃ´t de donnÃ©es, optimisÃ© pour l'analyse et le reporting. Il est composÃ© :

- D'une table de faits centrale (`FaitDonneesMeteo`) pour les mesures mÃ©tÃ©orologiques horaires.
- De tables de dimensions connectÃ©es (`DimLieux`, `DimConditionsMeteo`, `DimTemps`).

Ce choix facilite l'exploration des donnÃ©es et amÃ©liore les performances analytiques.

## Processus ETL et Algorithmes de Transformation

Les donnÃ©es brutes extraites de l'API ont Ã©tÃ© transformÃ©es pour passer dâ€™un format transactionnel Ã  une structure dÃ©normalisÃ©e adaptÃ©e au schÃ©ma en Ã©toile. Les Ã©tapes comprenaient :

- Parsing et validation des JSON via Pydantic.
- Mappage des attributs aux tables de faits et de dimensions.
- DÃ©composition des horodatages (annÃ©e, mois, jour, heure, minute) pour la dimension temps.
- Insertion des donnÃ©es transformÃ©es dans les tables via `pymysql`, en gÃ©rant explicitement les transactions pour assurer la cohÃ©rence.

## API de DonnÃ©es MÃ©tÃ©o

Une API a Ã©tÃ© dÃ©veloppÃ©e en Flask pour exposer les donnÃ©es de l'entrepÃ´t :

- `/trigger-etl` (GET) : DÃ©clenche le processus ETL en arriÃ¨re-plan.
- `/etl-status` (GET) : Statut actuel du processus ETL (en cours, terminÃ©, erreur).
- `/api/weather/all` (GET) : Toutes les donnÃ©es mÃ©tÃ©o disponibles.
- `/api/weather/locations` (GET) : Liste des villes disponibles.
- `/` (GET) : Sert le frontend (index.html).
- `/<path:filename>` (GET) : Sert les fichiers statiques (JS, CSS, etc.).

L'utilisation de Flask-Caching a permis dâ€™optimiser les rÃ©ponses, et le traitement ETL est exÃ©cutÃ© dans un thread sÃ©parÃ© pour ne pas bloquer les requÃªtes API.

## Cron-Jobs

La logique ETL a Ã©tÃ© encapsulÃ©e pour Ãªtre dÃ©clenchÃ©e par des tÃ¢ches planifiÃ©es (cron jobs), notamment via [cron-job.org](https://cron-job.org/) pour appeler `/trigger-etl`.

## Tableau de Bord et Validation

Un tableau de bord interactif a Ã©tÃ© dÃ©veloppÃ© avec React et des librairies de visualisation modernes. Il interroge directement lâ€™API Flask et permet une exploration dynamique et une validation des donnÃ©es.  

ğŸ”— **Tableau de bord en ligne** : [https://meteo-etl-dashboard.onrender.com/](https://meteo-etl-dashboard.onrender.com/)

## DÃ©fis ClÃ©s

- **Limitations des outils** : IncapacitÃ© dâ€™utiliser des ETL GUI (Talend, SSIS), nÃ©cessitant une approche codÃ©e.
- **Contraintes de ressources** : Limites CPU/RAM strictes, nÃ©cessitant des optimisations pour Ã©viter les plantages.
- **Contraintes DB** : ProblÃ¨mes de clÃ©s et relations, rÃ©solus par des insertions sÃ©quentielles et gestion explicite des transactions.

## IntÃ©gration Additionnelle (Airflow)

AprÃ¨s la finalisation du pipeline Python, un prototype local Airflow a Ã©tÃ© intÃ©grÃ© pour dÃ©montrer la comprÃ©hension des orchestrateurs utilisÃ©s en entreprise.

## LeÃ§ons Apprises

- Conception complÃ¨te d'un pipeline ETL, orchestration, gestion des erreurs et ressources.
- ComprÃ©hension de lâ€™Ã©quilibre entre simplicitÃ©, maintenabilitÃ© et conformitÃ© aux standards.
- Optimisation et dÃ©ploiement sous contraintes strictes.
- Pratique du dÃ©bogage et amÃ©lioration itÃ©rative basÃ©e sur les retours du systÃ¨me.

## Conclusion

Ce projet a permis dâ€™atteindre les objectifs fondamentaux dâ€™ETL et dâ€™entrepÃ´t de donnÃ©es tout en fournissant une expÃ©rience rÃ©aliste et orientÃ©e production.  
Il a renforcÃ© les compÃ©tences techniques et stratÃ©giques en ingÃ©nierie des donnÃ©es grÃ¢ce Ã  une combinaison de rÃ©solution de problÃ¨mes, conception de systÃ¨mes et flexibilitÃ© de pensÃ©e.

# ğŸš€ Configuration du flux d'air

```
. â”œâ”€â”€ airflow
â”‚ â”œâ”€â”€ airflow.cfg
â”‚ â”œâ”€â”€ airflow.db
â”‚ â”œâ”€â”€ dags
â”‚ â”‚ â””â”€â”€ weather_etl_dag.py
â”‚ â”œâ”€â”€ docker-compose.yml
â”‚ â”œâ”€â”€ dockerfile
```

---

## âœ… PrÃ©requis

* Docker et Docker Compose installÃ©s
* Connaissances de base du terminal

---

## ğŸ’¡ Contenu du dossier expliquÃ©

* `airflow.cfg` â€” Fichier de configuration Airflow
* `airflow.db` â€” Base de donnÃ©es SQLite locale pour les mÃ©tadonnÃ©es Airflow (si vous n'utilisez pas de base de donnÃ©es externe)
* `dags/` â€” Votre Les DAG se trouvent ici (par exemple, `weather_etl_dag.py`)
* `docker-compose.yml` â€” DÃ©finit les services et comment exÃ©cuter Airflow dans les conteneurs
* `dockerfile` â€” DÃ©finition d'une image personnalisÃ©e (par exemple, pour installer des packages supplÃ©mentaires)

---

## ğŸ—ï¸ CrÃ©er l'image Docker Airflow

Dans le rÃ©pertoire `airflow`Â :

```bash
cd airflow
docker build -t custom-airflow:latest -f dockerfile . ```

---

## âš™ï¸ VÃ©rifier / modifier `docker-compose.yml`

Assurez-vous que `docker-compose.yml` utilise l'image personnalisÃ©e que vous venez de crÃ©erÂ :

```yaml
versionÂ : '3'
servicesÂ :
airflowÂ :
imageÂ : custom-airflow:latest
environnementÂ :
- AIRFLOW__CORE__LOAD_EXAMPLES=False
- AIRFLOW__CORE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
volumesÂ :
- ./dags:/opt/airflow/dags
- ./airflow.cfg:/opt/airflow/airflow.cfg
- ./airflow.db:/opt/airflow/airflow.db
portsÂ :
- "8080:8080"
commandeÂ : Serveur web
```

---

## ğŸƒ DÃ©marrer Airflow

```bash
docker-compose up
```

* Ceci exÃ©cute le serveur web Airflow Ã  l'adresse **[http://localhost:8080](http://localhost:8080)**
* Par dÃ©faut, aucun ordonnanceur n'est exÃ©cutÃ© sÃ©parÃ©ment. Si nÃ©cessaire, ajoutez-le Ã  `docker-compose.yml` comme service supplÃ©mentaire.

---

## âš™ï¸ Initialiser la base de donnÃ©es (uniquement lors de la premiÃ¨re exÃ©cution)

Si c'est votre premiÃ¨re exÃ©cutionÂ :

```bash
docker-compose run airflow airflow db init
```

Puis redÃ©marrezÂ :

```bash
docker-compose up
```

---

## ğŸ” AccÃ©der Ã  l'interface utilisateur d'Airflow

* Ouvrir **[http://localhost:8080](http://localhost:8080)**
* Identifiants par dÃ©fautÂ : `airflow` / `airflow` (si inchangÃ©)

---

## âœ¨ VÃ©rifiez votre DAG

Dans l'interface utilisateur, vous devriez voir `weather_etl_dag.py` listÃ©.
Activez-le et dÃ©clenchez-le si nÃ©cessaire.

---

## ğŸ›‘ ArrÃªter Airflow

```bash
docker-compose down
```

---

## ğŸ’¬ Remarques

* Vous utilisez **SQLite**, parfait pour les tests locaux. En production, utilisez Postgres ou MySQL.
* Votre `airflow.db` est stockÃ© sous forme de fichier et montÃ©, ce qui garantit la persistance des donnÃ©es aprÃ¨s le redÃ©marrage du conteneur.
* Personnalisez `dockerfile` pour installer des packages Python ou des outils systÃ¨me selon vos besoins (par exemple, `RUN pip install requests`).


## âœ… RÃ©sumÃ©

1ï¸âƒ£ Construire votre image
2ï¸âƒ£ VÃ©rifier que `docker-compose.yml` pointe vers elle
3ï¸âƒ£ ExÃ©cuter `docker-compose up`
4ï¸âƒ£ AccÃ©der Ã  l'interface utilisateur Ã  `localhost:8080`

---
